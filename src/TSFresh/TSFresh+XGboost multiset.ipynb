{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb59a3ef",
   "metadata": {},
   "source": [
    "## TSFresh + XGBoost (r√©gression)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71126e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction.settings import EfficientFCParameters, MinimalFCParameters\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aedaeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SETS = [1, 2, 5, 7, 8, 10, 11]\n",
    "VAL_SETS = [3, 6, 12]\n",
    "TEST_SETS = [4, 9, 13]\n",
    "ALL_SETS = TRAIN_SETS + VAL_SETS + TEST_SETS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4642140",
   "metadata": {},
   "source": [
    "## fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edea215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_one_sensor_csv(csv_path, series_id=None, downsample=20):\n",
    "    \"\"\"Charge un fichier CSV de capteur et le formate pour TSFresh\"\"\"\n",
    "    csv_path = Path(csv_path)\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    if series_id is None:\n",
    "        series_id = csv_path.stem\n",
    "\n",
    "    sig = df.iloc[:, 0:5].copy()\n",
    "    sig.columns = [\"Acceleration\", \"AcousticEmission\", \"Fx\", \"Fy\", \"Fz\"]\n",
    "\n",
    "    dt = pd.to_datetime(df.iloc[:, -1], errors=\"coerce\")\n",
    "    if dt.isna().any():\n",
    "        raise ValueError(f\"{csv_path.name}: timestamps invalides.\")\n",
    "\n",
    "    time_sec = (dt - dt.iloc[0]).dt.total_seconds()\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"id\": series_id,\n",
    "        \"time\": time_sec,\n",
    "        \"Fx\": sig[\"Fx\"].astype(float),\n",
    "        \"Fy\": sig[\"Fy\"].astype(float),\n",
    "        \"Fz\": sig[\"Fz\"].astype(float),\n",
    "        \"Acceleration\": sig[\"Acceleration\"].astype(float),\n",
    "        \"AcousticEmission\": sig[\"AcousticEmission\"].astype(float),\n",
    "    }).sort_values(\"time\")\n",
    "\n",
    "    # Downsampling pour r√©duire le temps de calcul\n",
    "    if downsample and downsample > 1:\n",
    "        out = out.iloc[::downsample].reset_index(drop=True)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def to_tsfresh_long(df_wide: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convertit le format wide en format long pour TSFresh\"\"\"\n",
    "    return df_wide.melt(\n",
    "        id_vars=[\"id\", \"time\"],\n",
    "        value_vars=[\"Acceleration\", \"AcousticEmission\", \"Fx\", \"Fy\", \"Fz\"],\n",
    "        var_name=\"kind\",\n",
    "        value_name=\"value\",\n",
    "    )\n",
    "\n",
    "\n",
    "def load_labels_for_sets(labels_path, set_numbers, wear_type=[\"flank_wear\", \"flank_wear+adhesion\"]):\n",
    "    \"\"\"Charge les labels pour des sets sp√©cifiques\"\"\"\n",
    "    labels_raw = pd.read_csv(labels_path)\n",
    "\n",
    "    labels_filtered = labels_raw[\n",
    "        (labels_raw[\"Set\"].isin(set_numbers)) &\n",
    "        (labels_raw[\"type\"] == wear_type)\n",
    "    ].copy()\n",
    "\n",
    "    # Cr√©er l'ID √† partir du nom du fichier sensor\n",
    "    labels_filtered[\"id\"] = labels_filtered[\"SensorName\"].str.replace(\".csv\", \"\", regex=False)\n",
    "\n",
    "    # Ne garder que id et wear\n",
    "    labels_clean = labels_filtered[[\"id\", \"wear\"]].dropna().reset_index(drop=True)\n",
    "\n",
    "    return labels_clean\n",
    "\n",
    "\n",
    "def extract_features_for_files(csv_files, fc_params, verbose=True):\n",
    "    \"\"\"Extrait les features TSFresh pour une liste de fichiers CSV\"\"\"\n",
    "    all_features = []\n",
    "\n",
    "    for i, csv_path in enumerate(csv_files, start=1):\n",
    "        try:\n",
    "            df_wide = load_one_sensor_csv(csv_path)\n",
    "            df_long = to_tsfresh_long(df_wide)\n",
    "\n",
    "            X = extract_features(\n",
    "                df_long,\n",
    "                column_id=\"id\",\n",
    "                column_sort=\"time\",\n",
    "                column_kind=\"kind\",\n",
    "                column_value=\"value\",\n",
    "                default_fc_parameters=fc_params,\n",
    "                disable_progressbar=True,\n",
    "                n_jobs=1,\n",
    "            )\n",
    "            impute(X)\n",
    "            all_features.append(X)\n",
    "\n",
    "            if verbose and i % 10 == 0:\n",
    "                print(f\"Features extraites: {i}/{len(csv_files)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur avec {csv_path.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not all_features:\n",
    "        raise ValueError(\"Aucune feature extraite!\")\n",
    "\n",
    "    return pd.concat(all_features, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f42b5ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>Fx</th>\n",
       "      <th>Fy</th>\n",
       "      <th>Fz</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>AcousticEmission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_0015_1_00_000_2022-11-17T11_00_17.104150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>5.111</td>\n",
       "      <td>137.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_0015_1_00_000_2022-11-17T11_00_17.104150</td>\n",
       "      <td>0.012321</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>5.111</td>\n",
       "      <td>131.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_0015_1_00_000_2022-11-17T11_00_17.104150</td>\n",
       "      <td>0.024642</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>5.111</td>\n",
       "      <td>127.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_0015_1_00_000_2022-11-17T11_00_17.104150</td>\n",
       "      <td>0.036963</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>5.111</td>\n",
       "      <td>122.506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_0015_1_00_000_2022-11-17T11_00_17.104150</td>\n",
       "      <td>0.049284</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>5.111</td>\n",
       "      <td>118.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>Test_0015_1_00_000_2022-11-17T11_00_17.104150</td>\n",
       "      <td>39.981840</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>Test_0015_1_00_000_2022-11-17T11_00_17.104150</td>\n",
       "      <td>39.994161</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>Test_0015_1_00_000_2022-11-17T11_00_17.104150</td>\n",
       "      <td>40.006482</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>Test_0015_1_00_000_2022-11-17T11_00_17.104150</td>\n",
       "      <td>40.018803</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>Test_0015_1_00_000_2022-11-17T11_00_17.104150</td>\n",
       "      <td>40.031124</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3250 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 id       time     Fx     Fy  \\\n",
       "0     Test_0015_1_00_000_2022-11-17T11_00_17.104150   0.000000 -0.001 -0.002   \n",
       "1     Test_0015_1_00_000_2022-11-17T11_00_17.104150   0.012321  0.001 -0.002   \n",
       "2     Test_0015_1_00_000_2022-11-17T11_00_17.104150   0.024642 -0.003 -0.005   \n",
       "3     Test_0015_1_00_000_2022-11-17T11_00_17.104150   0.036963  0.000  0.001   \n",
       "4     Test_0015_1_00_000_2022-11-17T11_00_17.104150   0.049284 -0.001 -0.003   \n",
       "...                                             ...        ...    ...    ...   \n",
       "3245  Test_0015_1_00_000_2022-11-17T11_00_17.104150  39.981840 -0.002 -0.004   \n",
       "3246  Test_0015_1_00_000_2022-11-17T11_00_17.104150  39.994161 -0.000 -0.003   \n",
       "3247  Test_0015_1_00_000_2022-11-17T11_00_17.104150  40.006482 -0.004  0.003   \n",
       "3248  Test_0015_1_00_000_2022-11-17T11_00_17.104150  40.018803 -0.001 -0.003   \n",
       "3249  Test_0015_1_00_000_2022-11-17T11_00_17.104150  40.031124 -0.004 -0.004   \n",
       "\n",
       "         Fz  Acceleration  AcousticEmission  \n",
       "0    -0.037         5.111           137.888  \n",
       "1    -0.050         5.111           131.767  \n",
       "2    -0.043         5.111           127.861  \n",
       "3    -0.029         5.111           122.506  \n",
       "4    -0.053         5.111           118.620  \n",
       "...     ...           ...               ...  \n",
       "3245 -0.064         0.002             0.017  \n",
       "3246 -0.049         0.004             0.333  \n",
       "3247 -0.047        -0.009            -0.698  \n",
       "3248 -0.064        -0.002             0.064  \n",
       "3249 -0.049         0.004             0.757  \n",
       "\n",
       "[3250 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_one_sensor_csv(\"data/Test_0015_1_00_000_2022-11-17T11_00_17.104150.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c59be7",
   "metadata": {},
   "source": [
    "## 1. Load the labels for every sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af43b2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CHARGEMENT DES LABELS\n",
      "================================================================================\n",
      "\n",
      "Labels Train: 555 samples (Sets: [1, 2, 5, 7, 8, 10, 11])\n",
      "Labels Val:   170 samples (Sets: [3, 6, 12])\n",
      "Labels Test:  188 samples (Sets: [4, 9, 13])\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CHARGEMENT DES LABELS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "labels_train = load_labels_for_sets(\"labels.csv\", TRAIN_SETS)\n",
    "labels_val = load_labels_for_sets(\"labels.csv\", VAL_SETS)\n",
    "labels_test = load_labels_for_sets(\"labels.csv\", TEST_SETS)\n",
    "\n",
    "print(f\"\\nLabels Train: {len(labels_train)} samples (Sets: {TRAIN_SETS})\")\n",
    "print(f\"Labels Val:   {len(labels_val)} samples (Sets: {VAL_SETS})\")\n",
    "print(f\"Labels Test:  {len(labels_test)} samples (Sets: {TEST_SETS})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f33ee2",
   "metadata": {},
   "source": [
    "## 2. Load and extract features for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c1bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXTRACTION DES FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "fc_params = MinimalFCParameters()\n",
    "data_dir = Path(\"data\")\n",
    "\n",
    "# Dictionnaire pour stocker les features par set\n",
    "features_by_set = {}\n",
    "\n",
    "for set_num in ALL_SETS:\n",
    "    print(f\"\\n--- Set {set_num} ---\")\n",
    "\n",
    "    # Dossier du set : data/setX\n",
    "    set_dir = data_dir / f\"set{set_num}\"\n",
    "\n",
    "    if not set_dir.exists() or not set_dir.is_dir():\n",
    "        print(f\"  ‚ö†Ô∏è  Dossier introuvable: {set_dir}\")\n",
    "        continue\n",
    "\n",
    "    # Tous les CSV de ce set\n",
    "    csv_files = sorted(set_dir.glob(\"*.csv\"))\n",
    "\n",
    "    if not csv_files:\n",
    "        print(f\"  ‚ö†Ô∏è  Aucun fichier CSV trouv√© dans {set_dir}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"  Dossier: {set_dir}\")\n",
    "    print(f\"  Fichiers trouv√©s: {len(csv_files)}\")\n",
    "\n",
    "    # Extraire les features\n",
    "    X_set = extract_features_for_files(csv_files, fc_params, verbose=True)\n",
    "    features_by_set[set_num] = X_set\n",
    "\n",
    "    print(f\"  ‚úì Features extraites: {X_set.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c25fc47",
   "metadata": {},
   "source": [
    "## 3. Combine features by groups (train/val/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccfe573c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMBINAISON DES FEATURES\n",
      "================================================================================\n",
      "\n",
      "Features Train: (684, 3885)\n",
      "Features Val:   (371, 3885)\n",
      "Features Test:  (258, 3885)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMBINAISON DES FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "X_train_list = [features_by_set[s] for s in TRAIN_SETS if s in features_by_set]\n",
    "X_val_list = [features_by_set[s] for s in VAL_SETS if s in features_by_set]\n",
    "X_test_list = [features_by_set[s] for s in TEST_SETS if s in features_by_set]\n",
    "\n",
    "X_train_all = pd.concat(X_train_list, axis=0) if X_train_list else None\n",
    "X_val_all = pd.concat(X_val_list, axis=0) if X_val_list else None\n",
    "X_test_all = pd.concat(X_test_list, axis=0) if X_test_list else None\n",
    "\n",
    "print(f\"\\nFeatures Train: {X_train_all.shape if X_train_all is not None else 'N/A'}\")\n",
    "print(f\"Features Val:   {X_val_all.shape if X_val_all is not None else 'N/A'}\")\n",
    "print(f\"Features Test:  {X_test_all.shape if X_test_all is not None else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153dcc61",
   "metadata": {},
   "source": [
    "## 4. Align features with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc6030c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ALIGNEMENT FEATURES <-> LABELS\n",
      "================================================================================\n",
      "\n",
      "Train: 554/684 √©chantillons align√©s\n",
      "Val:   170/371 √©chantillons align√©s\n",
      "Test:  188/258 √©chantillons align√©s\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ALIGNEMENT FEATURES <-> LABELS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def align_features_labels(X_features, labels_df):\n",
    "    \"\"\"Aligne les features avec les labels sur les IDs communs\"\"\"\n",
    "    labels_indexed = labels_df.set_index(\"id\")[\"wear\"]\n",
    "    common_ids = X_features.index.intersection(labels_indexed.index)\n",
    "\n",
    "    X = X_features.loc[common_ids]\n",
    "    y = labels_indexed.loc[common_ids]\n",
    "\n",
    "    return X, y, common_ids\n",
    "\n",
    "if X_train_all is not None:\n",
    "    X_train, y_train, train_ids = align_features_labels(X_train_all, labels_train)\n",
    "    print(f\"\\nTrain: {len(train_ids)}/{len(X_train_all)} √©chantillons align√©s\")\n",
    "else:\n",
    "    X_train, y_train = None, None\n",
    "\n",
    "if X_val_all is not None:\n",
    "    X_val, y_val, val_ids = align_features_labels(X_val_all, labels_val)\n",
    "    print(f\"Val:   {len(val_ids)}/{len(X_val_all)} √©chantillons align√©s\")\n",
    "else:\n",
    "    X_val, y_val = None, None\n",
    "\n",
    "if X_test_all is not None:\n",
    "    X_test, y_test, test_ids = align_features_labels(X_test_all, labels_test)\n",
    "    print(f\"Test:  {len(test_ids)}/{len(X_test_all)} √©chantillons align√©s\")\n",
    "else:\n",
    "    X_test, y_test = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c77693",
   "metadata": {},
   "source": [
    "## 5. features selection on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723b7ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "S√âLECTION DE FEATURES\n",
      "================================================================================\n",
      "Features avant s√©lection: 3885\n",
      "Features apr√®s s√©lection: 1754\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"S√âLECTION DE FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if X_train is not None and y_train is not None:\n",
    "    print(f\"Features avant s√©lection: {X_train.shape[1]}\")\n",
    "\n",
    "    X_train_sel = select_features(X_train, y_train)\n",
    "    selected_features = X_train_sel.columns.tolist()\n",
    "\n",
    "    print(f\"Features apr√®s s√©lection: {len(selected_features)}\")\n",
    "\n",
    "    # Appliquer la m√™me s√©lection √† val et test\n",
    "    if X_val is not None:\n",
    "        X_val_sel = X_val[selected_features]\n",
    "    else:\n",
    "        X_val_sel = None\n",
    "\n",
    "    if X_test is not None:\n",
    "        X_test_sel = X_test[selected_features]\n",
    "    else:\n",
    "        X_test_sel = None\n",
    "else:\n",
    "    raise ValueError(\"Pas de donn√©es d'entra√Ænement disponibles!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd4cdcd",
   "metadata": {},
   "source": [
    "## 6. XGBoost Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe504b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ENTRA√éNEMENT XGBOOST\n",
      "================================================================================\n",
      "‚úì Mod√®le entra√Æn√©\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ENTRA√éNEMENT XGBOOST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "model = XGBRegressor(\n",
    "    n_estimators=600,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "model.fit(X_train_sel, y_train)\n",
    "print(\"‚úì Mod√®le entra√Æn√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffea55d",
   "metadata": {},
   "source": [
    "## 7. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717db758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "√âVALUATION\n",
      "================================================================================\n",
      "\n",
      "üìä TRAIN (Sets [1, 2, 5, 7, 8, 10, 11]):\n",
      "   MAE: 0.0018\n",
      "   R¬≤:  1.0000\n",
      "\n",
      "üìä VALIDATION (Sets [3, 6, 12]):\n",
      "   MAE: 57.3469\n",
      "   R¬≤:  -0.8509\n",
      "\n",
      "üìä TEST (Sets [4, 9, 13]):\n",
      "   MAE: 28.1231\n",
      "   R¬≤:  0.2522\n",
      "\n",
      "================================================================================\n",
      "TERMIN√â\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"√âVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Sur le train set\n",
    "pred_train = model.predict(X_train_sel)\n",
    "mae_train = mean_absolute_error(y_train, pred_train)\n",
    "r2_train = r2_score(y_train, pred_train)\n",
    "\n",
    "print(f\"\\nüìä TRAIN (Sets {TRAIN_SETS}):\")\n",
    "print(f\"   MAE: {mae_train:.4f}\")\n",
    "print(f\"   R¬≤:  {r2_train:.4f}\")\n",
    "\n",
    "# Sur le validation set\n",
    "if X_val_sel is not None and y_val is not None:\n",
    "    pred_val = model.predict(X_val_sel)\n",
    "    mae_val = mean_absolute_error(y_val, pred_val)\n",
    "    r2_val = r2_score(y_val, pred_val)\n",
    "\n",
    "    print(f\"\\nüìä VALIDATION (Sets {VAL_SETS}):\")\n",
    "    print(f\"   MAE: {mae_val:.4f}\")\n",
    "    print(f\"   R¬≤:  {r2_val:.4f}\")\n",
    "\n",
    "# Sur le test set\n",
    "if X_test_sel is not None and y_test is not None:\n",
    "    pred_test = model.predict(X_test_sel)\n",
    "    mae_test = mean_absolute_error(y_test, pred_test)\n",
    "    r2_test = r2_score(y_test, pred_test)\n",
    "\n",
    "    print(f\"\\nüìä TEST (Sets {TEST_SETS}):\")\n",
    "    print(f\"   MAE: {mae_test:.4f}\")\n",
    "    print(f\"   R¬≤:  {r2_test:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TERMIN√â\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26a96e7",
   "metadata": {},
   "source": [
    "## 8. Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccc4250b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Liste des features sauvegard√©e dans 'selected_features.txt'\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder la liste des features s√©lectionn√©es\n",
    "with open(\"selected_features.txt\", \"w\") as f:\n",
    "    for feat in selected_features:\n",
    "        f.write(feat + \"\\n\")\n",
    "\n",
    "print(f\"\\n‚úì Liste des features sauvegard√©e dans 'selected_features.txt'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
